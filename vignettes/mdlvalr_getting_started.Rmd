---
title: "mdlvalr_getting_started"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{mdlvalr_getting_started}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

## Introduction


This vignette will demonstrate how to use the `mdlvalr` package functions to generate a concordance analysis of data generated by the hybrid capture pipeline.



Load required packages.

```{r}
library(mdlvalr)
library(tidyverse)
library(glue)
library(openxlsx)
```


## Get input data. Use the provided example data that comes with the `mdlvalr` R package. 

Create variables for the analysis.


```{r}
# Set up output dir and names
# out_dir <- "/home/clinicalmdl/shared/disaster_recovery/ris/knut0297/r_package_mdlvalr/mdlvalr/vignettes"
out_dir <- normalizePath(".")
pipeline_name <- "hybcap"
input_data_dir <- "input_data"
curr_time <- format(Sys.time(), "%Y-%m-%d_%H%M%S")
output_data_dir <- glue("{pipeline_name}_concordance_{curr_time}")
```

Create and set a working dir.


```{r}
if (!dir.exists(glue("{out_dir}/{pipeline_name}/{input_data_dir}"))) {dir.create(glue("{out_dir}/{pipeline_name}/{input_data_dir}"), recursive = TRUE)}
setwd(glue("{out_dir}/{pipeline_name}/{input_data_dir}"))
```



Find a set of files (tarballs) that were outputs from the pipeline. Untar and uncompress the data if necessary.

```{r}
# Set working dir
out_dir <- normalizePath(".")
proj_name <- "concordance_hybcap"


# Find example data included with mdlvalr package
extdata_dir <- system.file("extdata", package = "mdlvalr", mustWork = TRUE)
tar_files <- list.files(extdata_dir, pattern = "*.tar.gz", full.names = TRUE, recursive = TRUE)


# Untar and uncompress files (if not already available)
for (i in seq_along(tar_files)) {
    curr_tar_path <- tar_files[i]
    # Find the top level dir name inside the tar.gz
	curr_top_level_dirname <- basename(untar(tarfile = curr_tar_path, list = TRUE)[1])
	
	if (!dir.exists(curr_top_level_dirname)) {
        untar(tarfile = curr_tar_path)
	} else {
	    message(glue("'{curr_top_level_dirname}' dir already exists - will not untar again."))
	}
}

```

Capture paths, sample names, etc. for the tar files and store the info in a data frame (e.g. tibble).

```{r}
cwd <- getwd()

samples_tbl <- tibble(tar_path = tar_files) %>%
    dplyr::mutate(tar_filename = basename(tar_path)) %>%
    dplyr::mutate(out_name = str_remove(tar_filename, ".tar.gz")) %>%
    dplyr::mutate(out_name = str_remove(out_name, "^output_")) %>%
    dplyr::mutate(sample_name = str_split(out_name, "_", simplify = TRUE)[, 2]) %>%
    dplyr::mutate(sample_name_short = str_remove(sample_name, "-[^-]*$")) %>%
    dplyr::mutate(sample_name_short = factor(sample_name_short)) %>%
    dplyr::mutate(group = str_extract(sample_name, "[^-]*$")) %>%
    dplyr::mutate(group = glue("{group}ng")) %>%
    dplyr::mutate(group = factor(group, levels = c("100ng", "150ng"))) %>%
    dplyr::mutate(run_name = str_split(out_name, "_", simplify = TRUE)[, 1]) %>%
    dplyr::mutate(run_ver = str_remove(out_name, fixed(as.character(glue("{run_name}_{sample_name}_"))))) %>%
    dplyr::mutate(filtered_path = glue("{cwd}/{out_name}/{sample_name}_{run_ver}_filtered_integrated_variant_output_summary.xlsx")) %>%
    dplyr::mutate(coverage_path = glue("{cwd}/{out_name}/{sample_name}_{run_ver}_coverage_summary.xlsx"))

```












Create and set an analysis-specific working dir.


```{r}
# Create output data dir
if (!dir.exists(glue("{out_dir}/{pipeline_name}/{output_data_dir}"))) {dir.create(glue("{out_dir}/{pipeline_name}/{output_data_dir}"), recursive = TRUE)}
setwd(glue("{out_dir}/{pipeline_name}/{output_data_dir}"))


```


Use the `validate_samples()` function to create an standardized "sample sheet" for the concordance analysis. This function will return a new tibble of data needed by downstream functions and check various assumptions about the comparison groups. 

```{r}
sample_sheet <- validate_samples(samples_tbl = samples_tbl, sample_name = "sample_name", sample_group = "sample_name_short", comparison_group = "group", var_path = "filtered_path", cov_path = "coverage_path", pipeline = "hybcap")
```

Load RefSeq GFF dataset (supplied with R package)

```
# Assign lazy data object to variable
invisible(refseq_gff_unnest_with_chrom_cds)
refseq_gff_unnest_with_chrom_cds <- refseq_gff_unnest_with_chrom_cds 
```


Run concordance

```{r}
rm(mdlvalr_list)
mdlvalr_list <- get_data(sample_sheet)
mdlvalr_list <- add_flags(mdlvalr_list, cds_table = cds_table, var_pass_fail_logic = "VAF >= 0.05", cov_pass_fail_logic = "fraction_125x >= 0.9")
mdlvalr_list <- compare_vars(mdlvalr_list)
mdlvalr_list <- add_var_labels(mdlvalr_list)
# Filter tables here??
mdlvalr_list <- get_stats(mdlvalr_list)
```





Create out files


```{r}
export_excel(mdlvalr_list, filename_prefix = "vaf_0.05_")
```




Zip up results


```{r}
setwd(glue("{out_dir}/{pipeline_name}"))
system(glue("tar czvf {output_data_dir}.tar.gz {output_data_dir}"), intern = TRUE)
```


